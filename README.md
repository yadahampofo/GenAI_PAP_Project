# Mutilingual Persuasive Adversarial Prompting Documentation
# PROJECT OVERVIEW

This project buildings upong the paper **How Johnny Can Persuade LLMs to Jailbreak Them:
Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs** by Incorporating a multilingual evaluation to see the sucessrates of Persuasive Adversarial Prompting across different languages. 

# MOTIVATION

Due to the widespread use of LLM across the globe ensuring that LLMs are safety aligned is of utmost priority. Scientists continue to explore vulnerabilities in an attempt to ensure that these pitfalls can immeediately be rectified. Previous publications have shown that Persuasive Adversarial Prompting has been sucessful in jailbreaking using a myriad of persuasion tecniques. However, an evalution of adversarial sucess rates these persuaive techniques across languages is yet to be investigated.

This project aims to bridge the gap in knowlege and explore adversarial sucess rates across three languages (French, English and Korean)

# TRANSLATOR API USED IN PROJECT
The DeepL API provides programmatic access to DeepLâ€™s machine translation technology, making it possible to bring high quality translation capabilities directly to your websites and applications
- Documentation about the Translator API can be read below:
- https://developers.deepl.com/docs 

#  Notes & Limitations
<br /> Created using code from https://github.com/CHATS-lab/persuasive_jailbreaker
<br /> Tech stack used: Python <br />
test
